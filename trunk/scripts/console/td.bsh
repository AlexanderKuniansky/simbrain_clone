/**
* Script to train an actor critic network for maze navigation. 
* The maze consists of a 3x3 grid. The cells are numbered from 
* (1,1) to (3,3). (1,1) is the starting state and (3,3) is the
* goal state (rewarding state).
*/
td() {
	int x = 1;
	int y = 1;
	// set the reward		
	workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(2).getNeuron(1).setInputValue(0);
	// set the inputs
	for(int j=0;j<9;j++){
		workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(0).getNeuron(j).setInputValue(0);
	}
	workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(0).getNeuron(0).setInputValue(1);
	workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().fireNetworkChanged();	
	
	for(int i=0;i<150;i++){
		print("\nCurrent position: " + x + "," + y);
		workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().updateRootNetwork();
		workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().fireNetworkChanged();				
		int action = workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getCurrentAction();
		
		switch(action){
			case 0: //right
				if(x < 3)
					x ++;
				break;
			case 1: //left
				if (x > 1)
					x --;
				break;
			case 2: //up
				if(y < 3 )
					y ++;
				break;
			case 3: //down
				if(y > 1)
					y --;
				break;
		}
		// set the inputs
		for(int j=0;j<9;j++){				
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(0).getNeuron(j).setInputValue(0);
		}
		int active = (x-1) * 3 + (y-1);
		workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(0).getNeuron(active).setInputValue(1);		
		
		if(x == 3 && y == 3){
			print("\nGoal reached\n\n");
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(2).getNeuron(1).setInputValue(1);
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().updateRootNetwork();
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().fireNetworkChanged();
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).reset();
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().fireNetworkChanged();	
			
			x = 1;
			y = 1;
			// set the reward		
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(2).getNeuron(1).setInputValue(0);
			// set the inputs
			for(int j=0;j<9;j++){
				workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(0).getNeuron(j).setInputValue(0);
			}
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(0).getNeuron(0).setInputValue(1);

		}else{
			// set the reward		
			workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).getNetwork(2).getNeuron(1).setInputValue(0);
		}
	}
	// clear everything before leaving
	workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().getNetwork(0).reset();
	workspace.getNetworkList().get(0).getNetworkPanel().getRootNetwork().fireNetworkChanged();	
}
