<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Simbrain Documentation</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link href="../../../Styles.css" rel="stylesheet" type="text/css" />
</head>

<body>
<a href="../../../SimbrainDocs.html"><div class="logo">
  <p><span></span></p>
</div>
</a>
<div id="main">
  <div class="navi">
   <p><a href="../../../SimbrainDocs.html">Simbrain</a> &gt; <a href="../../Network.html">Network</a> &gt; <a href="../network_op.html">Network Operations</a> &gt; <a href="../synapse.html">Synapse</a> &gt; Subtractive Normalization</p>
  </div>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p><h1>Subtractive Normalization Synapse</h1></p>
  <p span> <a href="hebbian.html">Hebbian learning</a> rules have the problem that they can make weights increase or decrease without limit. Several variants of Hebbian learning have been introduced to limit weight changes; subtractive normalization is one of them.
<p span>Subtractive normalization is  Hebbian learning, in which the sum of the weights attaching to a given neuron is kept relatively constant. This is achieved by subtracting the product of the target neuron activation <em>a<sub>t</sub></em> and the average activation of source neurons <em>a<sub>i</sub></em> attaching to <em>a<sub>t</sub></em>:

<blockquote>
  <p span="span"><img src="../equations/SubtractiveNormalization.png" width="241" height="85">
  </p>
</blockquote>
<p span>In order for the effect of keeping the sum of the weights  attaching to a neuron constant, those weights must obviously all use this rule. 
<p span>The strength of this synapse is <a href="../common.html#clipping">clipped</a> so as to remain between the lower and upper bounds specified for this synapse. Note that clipping the values of this type of synapse could interfere with its intended effect of keeping the sum of weights attaching to a neuron constant. 
<p span>Note that although this method constrains the sum of the weights to some fixed number, it allows for some weights to go off to positive infinity while others are going off simultaneously to negative infinity. 
<p span>See  Peter Dayan and Larry Abbott,<em> Theoretical Neuroscience, </em>Cambridge, MA: MIT Press, p. 290. 
<p span><span class="heading">Momentum</span>
<blockquote>
  <p span="span">The value which scales the rate of the change of this synapse, denoted by epsilon above. </p>
</blockquote>
</div>
</body>
</html>
