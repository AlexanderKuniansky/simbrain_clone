<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Vectors</title>
<link href="Styles.css" rel="stylesheet" type="text/css">
<link href="../Cogs103/middle.css" rel="stylesheet" type="text/css" />
<link href="../Cogs103/navi.css" rel="stylesheet" type="text/css" />
</head>

<body>
  <a href='../Cogs103/index.html'><div class="header"><span></span></div></a>
  <div id="navcontainer">
  <ul>
  <li> <a href="http://www.simbrain.net/Cogs103/Syllabus_COGS_103.doc">The Syllabus</a> </li>
  <li><a href="http://www.simbrain.net/Downloads/downloads_main.html">Simbrain Download</a> </li>
  <li><a href="../Lessons/Contents.htm">Lessons / Labs</a></li>
  <li><a href="http://lists.husserl.net/mailman/listinfo/cogs_103">Mailing List</a> </li>
  <li><a href="Homeworks.html">Homework</a></li>
  <li><a href="http://www.simbrain.net/index_new.html">The Simbrain Page</a> </li>
  </ul>
  <div class="body">
<p><span class="heading">Neural Networks as Dynamical Systems</span></p>
<p>One prevalent way of reconstructing the behavior of a neural network is in terms of dynamical systems theory. As a first pass, we can think of a dynamical system as a rule which tells us how a system changes its state over time. In the context of neural networks, a dynamical system will tell us how, given an initial assignment of activations to the neurons of a network (and assuming the weights are fixed), those activations will change over time. In fact, most neural networks just are dynamical systems: they provide us with a way to say how a set of neurons change their state over time. What dynamical systems theory adds is a mathematical and visual way for thinking about this. </p>
<p class="heading2"> Vector Spaces </p>
<p>Our first step in the direction of visually understanding the behavior of a neural network is to return to the discussion of vectors from a previous module and show how they correspond to points in a &quot;vector space.&quot;</p>
<p>Recall that a vector is a list of numbers, each of which is called a &quot;component,&quot; and that the dimension of a vector corresponds to how many components it has. Every vector of a given dimension can be thought of as a point in a vector space with that same number of dimensions. For example, this is a list of 2-dimensional vectors, which can be thought of as a set of points in a 2-dimensional vector space:</p>
<blockquote>
  <p>(0,0)<br>
(0,1)<br>
(1,0)<br>
(1,1)</p>
</blockquote>
<p>How do we turn these vectors in to point in a space? Well, you should all know how from high school algebra. We associate 2-dimensional vectors with points in a 2-dimensional space with treating each component as a location along one dimension of the space. For example, to find the point corresponding to the vector (5, 9) we move  5 units along the first x dimension and 9 units along the second y dimension to find our point. The examples above give us the corners of a square in the first quadrant of the plane. Here is another example:</p>
<blockquote>
  <p><img src="images/2dSpace.gif" width="173" height="104"></p>
</blockquote>
<p>The philosopher Rene Descartes is said to have come up with this method while observing flies on his ceiling. He observed that the position of the flies on the ceiling could be described with two numbers, in just this way. In fact, vectors and points are so closely related that  in what follows we use the two terms, &quot;point&quot; and &quot;vector&quot; interchangeably.</p>
<p>This idea can be generalized to vectors and spaces of any dimension. A vector, remember, is just a list of numbers. For 1-dimensional vectors this is easy: we just associate numbers with points on a line. We already saw how to do this for 2-dimensional vectors. We associate 3-dimensional vectors with points in a three-dimensional space (such as the one we live in), e.g. points bounded by a cubical region. In fact we have names for the first two dimensions: the line and the plane. </p>
<p>But what do we do about vectors which are more than three dimension? For example, these 5-dimensional vectors:</p>
<blockquote>
  <p>(0,-1, 1, .4, 9)<br>
(-1, 2, 4, -3, 9)<br>
(0, 0, 0, -1, -1 )<br>
(0, -1, 0, -1, 0 )<br> 
  </p>
</blockquote>
<p>We can't directly visualize a 5-dimensional space. So what is to be done?</p>
<p>With a lot of practice, mathematicians are able to obtain pretty good intuitions about these spaces, even though they can't be visualized. One thing you can do is think of the plane (a 2-d space) as a bunch of lines next to each other, and then 3-space is a bunch of planes next to each other. 4-spaces are then a bunch of 3-spaces next to each other, 5 spaces are a bunch of 4 spaces next to each other, and so forth. For a neat demonstration of this see <a href="http://www.cut-the-knot.org/ctk/Tesseract.shtml">this link.</a></p>
<p>Another piece of information that can be used in thinking about high dimensional spaces is <strong><em>distance</em></strong>. Vector spaces are &quot;metrizable,&quot; which means that between any two points a number called a &quot;distance&quot; can be computed (subject to a few additional constraints we won't go into here).  How this works is pretty intuitive. For example, (1,1) and (1,.9) are close to each other in the plane, as is fairly intuitive. The first component is the same and the second components just differ by .1. On the other hand, (0,5) and (-1000, 91234) are pretty far apart on both dimensions and hence in the plane. The same reasoning applies to high dimensional spaces. ( 0, 0, 0, 0, 1, 0) is close to ( 0, 0, 0, 0, .9, 0) but far away from ( 100, 99, 283, -102, 5, 23). </p>
<p>How do we compute this distance? There are multiple ways, but most of us are familiar with <strong>Euclidean distance</strong>, at least in practice. To get the distance between two points in 1-d space, we simply take the absolute value of the difference. E.g.,. 4 and 2 are | 2 - 4 | = 2 apart. To get the distance between two points (x<sub>1</sub>, y<sub>1</sub>) and (x<sub>2</sub>, y<sub>2</sub>) in a 2-dimensional space we take the square root of (x<sub>1</sub> - x<sub>2</sub>)<sup>2</sup> + (y<sub>1</sub> - y<sub>2</sub>)<sup>2</sup>. To get the distance between two points (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) and (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>) in a 3-dimensional space we take the square root of  (x<sub>1</sub> - x<sub>2</sub>)<sup>2</sup> + (y<sub>1</sub> - y<sub>2</sub>)<sup>2</sup> + (z<sub>1</sub> - z<sub>2</sub>)<sup>2</sup>. This easily generalizes to arbitrarily many dimensions. (See the <a href="http://en.wikipedia.org/wiki/Proximity">wikipedia entry on distance</a>.) </p>
<p class="heading2">Projections</p>
<p>In addition to allowing us to think intuitively about distances between points, distance information can be used to create <strong>projections</strong> from high dimensional spaces which we can't visualize to two or three dimensional spaces we can visualize. A projection is a way of representing a group of points in a high-dimensional space in a lower dimensional space. E.g. a representation of the three dimensional earth in a 2-dimensional plane is a projection.</p>
<p>A good projection will preserve as much distance information as possible. For example, Merced and Fresno are near each other on a globe, and also on a 2-d map, so this is a good projection. Another, less familiar example, is a &quot;boquet of three circles,&quot; which is a figure which lives in spaces of six dimensions or more. A boquet of three circles is a set of three circles, each lying on its own 2-d plane, which intersect at a single point. This object exists in at least 6 dimensions, but can be projected to 2-dimensions and thereby visualized:</p>
<p><img src="images/S1VS1VS1_Sammon.gif" width="300" height="300"></p>
<p>The software that was used to do the visualization is part of Simbrain (it was created by one of the authors and a mathematician, Scott Hotton; for more information click <a href="http://hisee.sourceforge.net/">here</a>), and so can be used to visualize structures in the high dimensional activation, weight, and input spaces of a neural network. </p>
<p>We will see that projections give us a way of dealing the high dimensional dynamical systems, like neural networks, in familiar 2 and 3 dimensional spaces. </p>
<p class="heading2">States and State Spaces </p>
<p>Let us now develop the ideas of dynamical systems theory systematically, from the ground up, in a manner that connects it with neural networks. Let us begin with the concept of a state. </p>
<blockquote>
  <p><strong>State</strong>: 


A specification of values for all the variables describing a system.&nbsp; For the most part, we will take the state of a network to correspond to an activation vector (which specifies the activations of a set of nodes). However, we can also treat weight vectors, input vectors, or output vectors as states. </p>
</blockquote>
<p>Recall from on earlier module that there are several standard features of neural networks which are understood as vectors: activation vectors, weight vectors, and input / output vectors.  We can also think of these as describing the &quot;state&quot; of the neural network: its activation state, its weight state, the state of inputs to it, etc. Among these, activation vectors are most commonly thought of as describing the state of the network. Unless otherwise mentioned, then, we will think of an activation vector as corresponding to the state of a network.</p>
<blockquote>
  <p><strong>State Space</strong>: the set of possible states of a system. This is called an &quot;activation space&quot; for activation vectors, a &quot;weight space&quot; for weight vectors, etc.  </p>
</blockquote>
<p>We  saw above that one can visualize vectors as points in a space, and we have also seen that the state of a neural network corresponds to a vector. Thus the set of all possible states of a neural network, its state space, corresponds to a set of points in a space. The number of dimensions of a state space corresponds to the number of components in the corresponding activation vectors, weights vectors, etc. For example, the state of a 20-node network is given by a 20-dimensional activation vector, which is a state in a 20-dimensional activation space. </p>
<p>Let us consider an example, which can be accessed by opening <span class="command">workspace &gt; lessons &gt; projection.xml</span>. The network in this example is a very simple network which reacts to objects around it. The network has four neurons, two input neurons each of which can taken on any value between 0 and 5, and binary outputs with a threshold of 3. The network is a very simple object detector, which responds to either fish or cheese but, because of the cross-cutting inhibitory synapses, does not respond to both together. </p>
<p>Since the network has four neurons, any pattern of activity in it is a 4-dimensional activation vector, that is, a point in a four dimensional activation space. As the network runs, reacting to the fish and cheese, different patterns of activity occur corresponding to different points in the four dimensional activation space. In the picture below, we see a projection of the activation space to two dimensions on the left. The red point is the point corresponding the <em>current state</em> of the network, the activation vector, (1, 0, 5, 0). Try moving the mouse around and you will that the different points turn red as the state of the network changes.</p>
<p><img src="images/GaugeExample1.png" width="842" height="276"></p>
<p>The structure of the points in the activation space is interesting. There are two line-segments, one corresponding to each object. The furthest point on each line segment corresponds to maximal exposure to one of the two objects. The intermediate points correspond to states where the mouse is some intermediate distance from the an object. And the point where the two line segments meet is the origin, (0,0,0,0). </p>
<p>Even though we are looking at a projection, the distances are meaningful. The points which are furthest apart are the maximal exposures to fish and cheese, and the point in the middle of the two is state which corresponds to seeing nothing. So you see we have a visual way of understanding the way the neural networks represents its environment over time.</p>
<p>Another point about activation spaces is that they can be broken down into subspaces. Instead of thinking of the above as a vector in 4-space, we can think of it as involving two vectors in 2-space, an input vector and an output vector.  We can separately plot these as follows:</p>
<p><img src="images/GaugeSubspace.png" width="435" height="223"></p>
<p>Note that the input space is a lot like the total activation space, just a bit smoother (there are &quot;bumps&quot; in the total space which come from the output node activities). The output space is just three points. One corresponding to recognizing cheese, one corresponding to recognizing fish, and one corresponding to seeing nothing. There is no point (1,1) corresponding to seeing both fish and cheese, because the inhibitory synapses prevent that. </p>
<p>Let us briefly mention weight space and input space. Weight vectors are also points in a space with as many dimensions as there are weights (here it is easier to think of sets of weights as list vectors than as matrices, even though matrices are, in the strict mathematical sense, themselves vectors). For example, in the network above there are 4 synapses, and thus we have a point in a 4 dimensional &quot;weight space.&quot; Each point in weight space corresponds to a different set of weights, and hence a different manner of processing inputs and outputs, a different vector-valued function. We can imagine that points nearby will compute similar functions, while points far apart compute different functions. Inputs are also point in a vector space. This allows us to compare and directly analyze the stimuli to a network. In the rest of this module we focus almost entirely on activation vectors and activation spaces.</p>
<p class="heading2">Dynamical Systems</p>
<p>We are now in a position to define basic concept of dynamical systems theory. We saw that the state of a system is a point in a space, and that a state space is the set of all states of a system. The state space is like our window on the system; it will let us see all sorts of things about its behavior. In Simbrain the gauge windows correspond to projections of activation space, and hence serve this function.</p>
<p>We begin with the concept of an initial condition, which is just a point in state space which we assume our system begins in. </p>
<blockquote>
  <p><strong>Initial Condition</strong><span class="heading2">:</span> the state a system begins in.</p>
</blockquote>
<p>For neural networks, this is a specification of values for its nodes, that is, an  activation vector.  When we  set the neurons at some level of activation we are setting the network in an initial condition. Often we arbitrarily choose the initial condition. In Simbrain we do this by selecting all the nodes of a network and then pressing the random button. If we repeatedly press the random button we end up putting the network in a whole bunch of initial conditions.</p>
<p>Now we are in a position to give a definition of a dynamical system:</p>
<blockquote>
  <p><strong>Dynamical system</strong>: A rule which tells us what state a system will be in at any future time, given any initial condition.</p>
</blockquote>
<p>A dynamical system can be thought of visually as a recipe for saying, given any point in state space, what points the system will go to at all future times: if the system begins here at this point at noon on Thursday, it will be at this other point at 5pm on Friday. And we can do this no matter what initial condition we find our system in. Thus dynamical systems are <em>deterministic</em>, they allow us to completely predict the future based on the present. </p>
<p>Pendula provide a classical example of a dynamical system: if you start the pendulum off in some beginning state, we can say exactly how it will swing forever in to the future, at least in principle. Most neural networks are also dynamical systems. If you start the neural network off in some state--if you specify values for all its nodes--then based on its update rules and the way it is wired together we can say for all future times how it will behave. Thus, &quot;running&quot; a neural network, in Simbrain by pressing the <span class="command">step</span> or the <span class="command">play</span> button, corresponds to applying the dynamical rule that corresponds to it. A neural network which is predictable in this way is a dynamical system. Can you think of ways to make a neural network <em>not</em> be a dynamical system? We will discuss this below. </p>
<p> It may have occurred to you that we can actually visualize dynamical systems using the methods described above. Can you say how? Hold that thought. First let's introduce another concept, that of an &quot;orbit.&quot; </p>
<blockquote>
  <p><strong>Orbit</strong>: the set of states that are visited by a dynamical system from an initial condition. These are also known as trajectories.</p>
</blockquote>
<p>So, we put the neural network in some initial state, and then we run the network. It  changes state as a result. All of its activations change. Each time the neural network changes state we have a new point in activation space. If we look at all the states that result from an initial condition we get an orbit. An orbit describes one of the possible behaviors of a dynamical system over time. You put it arbitrarily in some starting state, and then, since it is a deterministic system, it's future is set. The initial condition together with its future states is an orbit. For continuous systems these look like curves, and they are easy to visualize. For discrete systems, like the neural networks implemented in Simbrain, orbits can jump around from state to state and are harder to visualize. For example, this is an example of an orbit in a three node Simbrain network:</p>
<blockquote>
  <p>(0, .3, .9) &gt; (1, 0, -1) &gt; (-1, 1, 1) &gt; (-1, -1, 1) &gt; (1, -1, -1) &gt; (1, 1, -1) &gt; (-1, 1, 1) &gt; (-1, 1, 1) &gt; .... </p>
</blockquote>
<p>Notice that after a while this system begins repeating the same states over and over (it will continue to do so for all of time): this is called a &quot;periodic orbit,&quot; and will be discussed below. </p>
<p>I asked above if you could think of a way to visualize a dynamical system, in light of what has been said so far. All the pieces are now in place. To do this, we simply draw all the orbits in state space. This will show us, visually, what the set of all behaviors of a system looks like. </p>
<blockquote>
  <p><strong>Phase portrait</strong>: A picture of a state space with important orbits draw in it.</p>
</blockquote>
<p>Of course, if we drew every orbit, it will fill the whole page up, so we just draw the important ones that are most revealing. And of course, since most neural networks have more than 3 nodes, we will typically have to visualize a phase portrait in a projection, like the gauges in Simbrain. </p>
<p> Here are a few sample phase portraits:</p>
<table width="200" border="0" cellspacing="10" cellpadding="10">
  <tr>
    <td><img src="images/Flow1.jpg" width="273" height="196"></td>
    <td><img src="images/flow2.gif" width="268" height="206"></td>
  </tr>
</table>
<p>These can be thought of phase portraits for 2-dimensional systems, i.e. 2-neuron neural networks. Again, any point in one of these diagrams corresponds to a state of the network. If you start in some random state, some initially condition, then the lines with arrows tell you where you will go in the future. They lines with arrows are orbits.  </p>
<p>Note that the way orbits looks in a projection may be different from the way they really are; in particular, orbits can cross each other in a projection, but cannot cross each other in actuality. Also note that the orbit for a discrete dynamical system, i.e.,. a Simbrain network, will not involve smooth curves as in the pictures above.</p>
<p class="heading2">Open Systems, Closed Systems, and Recurrent Networks </p>
<p>The neural networks depicted above is not, strictly speaking, a dynamical system, because we cannot predict precisely what it will do from some fixed starting state. If you set the neurons at some level it can do different things, depending on what inputs are sent to it.  The problem is that the neural network above is <em>open</em> to its environment. A true dynamical system is fully predictable (&quot;deterministic&quot;), and to get that predictability, we have to shut it off from its environment, we have to make it in to a &quot;closed system.&quot; We can always do this in Simbrain simply by clicking the interaction button until the <img src="images/NeitherWay.gif" width="18" height="18">, appears, which means the net is not interacting with the world and the world is not interacting with networks. We can also do this simply by not creating any worlds.</p>
<p>So, suppose you have a  neural network closed off from any environment, from any &quot;world.&quot; This will be, almost automatically, a dynamical system (how can you make this <em>not </em>be a dynamical system? Some ways you could do this are to add noise to a neuron, or to use a random neuron or synapse, in which case we could not predict what it will do). However, most of the neural network's we've looked at have been <em>boring.</em>For example, the network below has boring dynamics on its own:</p>
<p><img src="images/Feedforward.png" width="278" height="187"></p>
<p>What makes the difference between a boring and interesting neural network from the standpoint of dynamical systems theory? The answer, roughly, is how much they will change their state when closed off. In the feed-forward networks shown above, when you put some activity in to the network it immediately propagates along the connections and disappears. In one or two time steps the network is back in its zero state. </p>
<p>How can we make our neural networks exhibit more interesting dynamics, where activity does not just dissipate out but actually changes in an interesting way over time, independently of external inputs? The answer is simple: make some of the connections between neurons go &quot;backwards,&quot; as it were, so that activity will not just dissipate but will flow in loops back on itself. This is called <strong>recurrence</strong>. Here is an example of a recurrent network:</p>
<p><img src="images/recurrent_network.png" width="280" height="221"> </p>
<p>If you put this network in some initial state it may flicker around for a while before &quot;settling down.&quot; And it may never settle down at all. It may end up cycling through a few different states over time.</p>
<p class="heading2">Attractors, Repellors, Fixed Points, and Periodic Orbits </p>
<p>Not all the states of a dynamical system are equally interesting. There are some states it will hardly ever be in, and there are some it will almost always be in. If we measure a dynamical system we are likely to see it one of its <em>stable states</em>, as opposed to an unstable state. For example, objects are usually observed at rest, as opposed to being balanced in precarious ways. Similarly, though there are many different possible states of the brain, there are only a few that we will tend to see in practice, namely, those that it is wired up to produce. In this section we introduce some language for talking about these different kinds of states. </p>
<p>First, another definition: </p>
<blockquote>
  <p><strong>Invariant set</strong>: a collection of orbits. Everything in an invariant set stays in an invariant set. </p>
</blockquote>
<p>An invariant set is just a collection of orbits, and it is &quot;invariant&quot; in that if a system begins somewhere in an invariant set, it will stay in there for all time (unless some external force pushes it out of the set, but then it is no longer a dynamical system). Now, the concept of an invariant set is not that interesting on its own, but it allows us to introduce some new concepts which are useful for understanding the different states of a dynamical system.</p>
<p>There are at least two different ways we can classify invariant sets. First, we can classify them by their &quot;topology&quot; or shape. There are two especially interesting shapes for invariant sets: </p>
<blockquote>
  <p><strong>Fixed point</strong>: a state that goes to itself under a dynamical system. The system &quot;stays&quot; in this state forever. </p>
  <p><strong>Periodic Orbit</strong>: a set of points that the dynamical system visits repeatedly and in the same order. The system cycles through these states over and over. The number of states in a periodic orbit is its &quot;period.&quot; These are also known as limit cycles (when they are continuous curves). </p>
</blockquote>
<p>Fixed points and periodic orbits are two particular shapes that invariant sets have. Fixed points are single points. Periodic orbits are repeating loops. Can you guess which is more likely to be observed in the brain? Yes, periodic orbits, that is, oscillations. The brain never stays completely still. Note that there are other shapes for invariant sets. For example, some really interesting invariant sets are &quot;chaotic&quot; or &quot;quasi-periodic,&quot; but we will not deal with these here. </p>
<p>We can count how many points there are in a periodic orbit, and that corresponds to the &quot;period&quot; of the periodic orbit. For example, a period-2 periodic orbit consists of two points that a neural network cycles through over and over again. A period 3 periodic orbit consists of three points it cycles through, etc. Don't confuse the period of a periodic orbit with the number of periodic orbits a system has. For example, a system might have four periodic orbits, one of period 2, and three of period 3. </p>
<p>Another way we can classify invariant sets is according to the way states nearby the invariant set behave. Sometimes states near an invariant set will tend to go to that set. The invariant set &quot;pulls in&quot; nearby points. These are the stable states, the ones we are likely to see. Other times states near an invariant set will tend to go away from it. These are the unstable states, the ones we are unlikely to see. </p>
<blockquote>
  <p><strong>Attractor</strong>: a state or set of states <em>A</em> with the property that if you are in a nearby state the system will always go towards <em>A</em>. Fixed points and periodic orbits can both be attractors . These are the states of a system you will tend to observe. These are also known as equilibria or stable states.</p>
  <p><strong>Repellor</strong>: a state or set of states <em>R</em> with the property that if you are in a nearby state the system will always go away from <em>R</em>. Fixed points and periodic orbits can both be repellors. You are not likely to see these in practice. These are also known as unstable states.</p>
</blockquote>
<p>One way to think about attractors and repellors is in terms of the possible states of a penny. When the penny is lying on one face or the other, it is in an attractor, a stable fixed point: if you perturb it a little it just falls back to the same place. If you balance the penny on its edge, however, it is on a repelling fixed point. If you perturb it a little in these states it will not go back to the edge-state, but will fall over. </p>
<p>In the chart below, the columns correspond to different topologies or shapes that a invariant set can have. The rows corresponds to the behavior of nearby states.</p>
<div align="center">
  <table width="403" border="1" cellpadding="5" cellspacing="0" bordercolor="#000000">
    <tr>
      <td width="56">&nbsp;</td>
      <td width="120"><strong>Fixed Point</strong></td>
      <td width="120"><strong>Periodic orbit </strong></td>
      <td width="120">Other </td>
    </tr>
    <tr>
      <td><strong>Attractor</strong></td>
      <td><strong>attracting fixed point </strong></td>
      <td><strong>attracting periodic orbit </strong></td>
      <td>chaotic attractor, quasi-periodic attractor </td>
    </tr>
    <tr>
      <td><strong>Repellor</strong></td>
      <td><strong>repelling fixed point </strong></td>
      <td><strong>repelling periodic orbit </strong></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Other </td>
      <td>centers, saddle nodes </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </table>
  <blockquote>
    <blockquote>&nbsp;</blockquote>
  </blockquote>
</div>
<p>The stuff in bold is the stuff we will talk about in this course. </p>
<p>Now, one final idea will be important for dynamical systems in neural network theory. </p>
<blockquote>
  <p><strong>Basin of attraction</strong>: the set of all states that tend towards a given attractor. Each attractor has its own basin of attraction. </p>
</blockquote>
<p>An important thing to do when studying a neural network as a dynamical system is to find all the attractors, because these are the states the network will tend to be in. But it is also interesting to ask which states are &quot;drawn&quot; to a particular attractor. The set of all points attracted to a particular attractor is called a basin of attraction. You start a system off somewhere in a basin of attraction and it will end up, eventually, on or near that basin's attractor.   One convenient metaphor for understanding basins of attraction  is via a landscape or hill-and-valley metaphor. We can think of the state space of a neural network as being a curved surface, and the attractors as being valleys. The state of the network can be thought of as a marble on this surface, which will roll along paths (orbits) to the nearest valley. The basin of an attractor is the literal basin surrounding a low point.</p>
<p>There is much more to say about with dynamical systems theory relative to neural networks, but that's a good start.</p>
<p class="heading2">What does all this have to do with neural networks?</p>
<p>At this point you may be wondering why we should care about all this stuff, relative to neural network theory. How will this help us with cognitive science? One very general answer is that it gives us a visual way of understanding the way neural networks and the brain work. I'll say a few more words about this in the final section on &quot;philosophy&quot; below. But there are other examples that may help.</p>
<p>One popular way of viewing dynamical systems ideas relative to neural network theory is in terms of the fully connected recurrent networks above, which are sometimes also called &quot;attractor networks.&quot; In these networks, the attractors are thought of as memories. If a network has 20 attractors, we think of it as having 20 memories. Learning new memories corresponds to acquiring new attractors. The process of moving from somewhere in a basin of attraction to the attractor corresponds to recalling the memory. We will play with these types of networks in another module. </p>
<p>A related  example is perceptual completion. Suppose you see part of an image, but then are able to remember the rest of it. We can think of the state of seeing just part of the image as causing an initial condition state in a neural network, and the process of &quot;filling in&quot; the rest of the image as the network's process of heading to the nearest attractor. </p>
<p>There are many other examples, some of which we will see in later modules. </p>
<p class="heading2">Philosophy</p>
<p>Philosophically, dynamical systems theory has provided cognitive science with a useful conceptual framework for understanding the relation between mind and brain in general. </p>
<p>The whole brain can be thought of as being described by a huge state vector: a 100-billion dimensional vector each of whose components corresponds to the firing of some one of my 100-billion neurons. The state space of the entire brain, the set of all possible patterns of firing for a given person's brain, is then a region of a 100-billion dimensional space. These vectors can be broken down into subvectors, and the whole space can be broken down into subspaces. For example, we can break the state of the whole brain down into subsets corresponding to the activity of visual cortex, auditory cortex, etc. The state of the visual cortex, which represents a visual scene in the world, is a pattern of activity over several million neurons, a million dimensional vector, which is a point in a million dimensional space. We can now compare different states of the visual cortex by how close or far they are in &quot;visual cortex space.&quot; We can imagine that visual experiences of similar objects in similar lighting conditions are close to each other, while visual experiences of different objects are far away, and if we plotted these as points we would see the relevant distance relations.</p>
<p>All of this is very exciting in terms of understanding how the mind and brain work. We see the possibility of construing mental and neural activity in a way that can be visualized and mathematically analyzed. The possibility is opened of a geometry of mental processing. As the philosopher Paul Churchland put it in a 1986 article in <em>Mind</em>: </p>
<blockquote>
  <p>The basic idea&hellip;&nbsp; is that the brain represents various aspects of reality by a <em>position</em> in a suitable <em>state-space</em>; and the brain performs computations on such representations by means of general coordinate transformations from one state-space to another&hellip; The theory is entirely accessible&mdash;indeed, in its simplest form [under 3 dimensions] it is <em>visually</em> accessible (280). </p>
  <p>&nbsp;</p>
</blockquote>
<p class="heading2">Study Questions</p>
<p>Give examples of three six-dimensional vectors, two of which are closer to each other than they are to the third.</p>
<p>Draw a plausible projection of the three vectors in the last example to a 2-dimensional space. </p>
<p>Suppose a neural network has five nodes, two of which are linked to an environment.&nbsp; Is it an open or closed system?</p>
<p>Describe two ways a neural network can fail to be a dynamical system.</p>
<p>Suppose you have observed the following orbits in a three node network:</p>
<blockquote>
  <p>(0,0,0) &gt; (0, 0, 0)<br>
    (1,1,1) &gt; (1,1,1)<br>
    (-1,1,1) &gt; (1, -1, -1) &gt; (-1,1,1)<br>
    (-1, 0,-1) &gt; (0, -1, 0) &gt; (0,0,1) &gt; (1, 1, 0) &gt; (-1, 0,-1)</p>
  <p>How many fixed points does this network have?</p>
  <p>How many periodic orbits does this network have?</p>
  <p>What are the periods of its periodic orbits?</p>
</blockquote>
<p>Given a fixed point, how do you determine whether it is an attractor or a repellor?</p>
<p class="heading2">&nbsp; </p>
<p class="heading2">References</p>
<p><a href="http://hisee.sourceforge.net/">HiSee</a></p>
<p><a href="http://maven.smith.edu/%7Ezeno/">Scott Hotton</a></p>
<p><a href="http://www.nsi.edu/users/izhikevich/">Eugene M. Izhikevich</a></p>
<p>&nbsp;</p>
</body>
</html>
