<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Vectors</title>
<link href="Styles.css" rel="stylesheet" type="text/css">

</head>

<body>
<p><span class="heading">Neural Networks as Dynamical Systems</span></p>
<p>One prevalent way of reconstructing the behavior of a neural network is in terms of dynamical systems theory. As a first pass, we can think of a dynamical system as a rule which tells us how a system changes its state over time. In the context of neural networks, a dynamical system will tell us how, given an initial assignment of activations to the neurons of a network (and assuming the weights are fixed), those activations will change over time. In fact, most neural networks just are dynamical systems: they provide us with a way to say how a set of neurons change their state over time. What dynamical systems theory adds is a mathematical and visual way for thinking about this. </p>
<p>Since the presentation in these modules is relatively non-technical, we will develop these ideas in a visual manner. </p>
<p class="heading2">Vector Spaces </p>
<p>Our first step in the direction of visually understanding the behavior of a neural network is to return to the discussion of vectors from a previous module and show how they correspond to points in a &quot;vector space.&quot;</p>
<p>Recall that a vector is a list of numbers, each of which is called a &quot;component,&quot; and that the dimension of a vector corresponds to how many components it has. Every vector of a given dimension can be thought of as a point in a vector space with that same number of dimensions. For example, this is a list of 2-dimensional vectors can be thought of as a set of <strong>points</strong> in a 2-dimensional vector space:</p>
<blockquote>
  <p>(0,0)<br>
(0,1)<br>
(1,0)<br>
(1,1)</p>
</blockquote>
<p>How do we turn these vectors in to point in a space? Well, you should all know how from high school algebra. We associate 2-dimensional vectors with points in a 2-dimensional space with treating each component as a location along one dimension of the space. For example, to find the point corresponding to the vector (5, 9) we move  5 units along the first x dimension and 9 units along the second y dimension to find our point. The examples above give ius the corners of a square in the first quadrant of the plane. Here is another example:</p>
<blockquote>
  <p><img src="images/2dSpace.gif" width="173" height="104"></p>
</blockquote>
<p>The philosopher Rene Descartes is said to have come up with this method while obvserving flies on his ceiling. He observed that the position of the flies on the ceiling could be described with two numbers, in just this way. In fact, vectors and points are so closely related that  in what follows we use the two terms, &quot;point&quot; and &quot;vector&quot; interchangably.</p>
<p>The point can be generalized to vectors and spaces of any dimension. A vector, remember, is just a list of numbers. For 1-dimensional vectors this is easy: we just associate numbers with points on a line. We already saw how to do this for 2-dimensional vectors. We associate 3-dimensional vectors with points in a three-dimensional space (such as the one we live in), e.g. points bounded by a cubical region. In fact we have names for the first two dimensions: the line and the plane. </p>
<p>But what do we do about vectors which are more than four dimension? For example, these 5-dimensional vectors:</p>
<blockquote>
  <p>(0,-1, 1, .4, 9)<br>
(-1, 2, 4, -3, 9)<br>
(0, 0, 0, -1, -1 )<br>
(0, -1, 0, -1, 0 )<br> 
  </p>
</blockquote>
<p>We can't directly visualize a 5-dimensional space. So what is to be done?</p>
<p>With a lot of practice, mathematicians are able to obtain pretty good intuitions about these spaces, even though they can't be visualized. One thing you can do is think of the plane (a 2-d space) as a bunch of lines next to each other, and then 3-space is a bunch of planes next to each other. 4-spaces are then a bunch of 3-spaces next to each other, 5 spaces are a bunch of 4 spaces next to each other, and so forth. For a neat demonstration of this see <a href="http://www.cut-the-knot.org/ctk/Tesseract.shtml">this link.</a></p>
<p>Another piece of information that can be used in thinking about high dimensional spaces is <strong><em>distance</em></strong>. Vector spaces are <strong>metric spaces</strong>, which means that between any two points a number called a &quot;distance&quot; can be computed (subject to a few additional constraints we won't go into here). How this works is pretty intuitive. For example, (1,1) and (1,.9) are close to each other in the plane, and intuitively also. The first component is the same and the second components just differ by .1. On the other hand, (0,5) and (-1000, 91234) are pretty far apart on both dimensions and hence in the plane. The same reasoning applies to high dimensional spaces. ( 0, 0, 0, 0, 1, 0) is close to ( 0, 0, 0, 0, .9, 0) but far away from ( 100, 99, 283, -102, 5, 23). </p>
<p>How do we compute this? There are multiple ways, but most of us are familiar with <strong>Euclidean distance</strong>, at least in practice. To get the distance between two points in 1-d space, we simply take the absolute value of the difference. E.g,. 4 and 2 are | 2 - 4 | = 2 apart. To get the distance between two points (x<sub>1</sub>, y<sub>1</sub>) and (x<sub>2</sub>, y<sub>2</sub>) in a 2-dimensional space we take the square root of (x<sub>1</sub> - x<sub>2</sub>)<sup>2</sup> + (y<sub>1</sub> - y<sub>2</sub>)<sup>2</sup>. To get the distance between two points (x<sub>1</sub>, y<sub>1</sub>, z<sub>1</sub>) and (x<sub>2</sub>, y<sub>2</sub>, z<sub>2</sub>) in a 3-dimensional space we take the square root of  (x<sub>1</sub> - x<sub>2</sub>)<sup>2</sup> + (y<sub>1</sub> - y<sub>2</sub>)<sup>2</sup> + (z<sub>1</sub> - z<sub>2</sub>)<sup>2</sup>. This easily generalizes to arbitrarily many dimensions. (See the <a href="http://en.wikipedia.org/wiki/Proximity">wikipedia entry on distance</a>.) </p>
<p>In addition to allowing us to think intuitively about distances between points, distance information can be used to create <strong>projections</strong> from high dimensional spaces which we can't visualize to two or three dimensional spaces we can visualize. A good projection will preserve as much distance information as possible. We are all familiar with flat projections of the earth, which take a 3-dimensional object (a globe) and show it in a lower dimensional space (a map of the earth). Merced and Fresno are near each other on the 2-d map, and they are near each other on the globe, so this is a good projection. Another, less famililar example, is a &quot;boquet of circles,&quot; which is a figure in six dimensional space, which is set of three circles, each lying on its own 2-d plane, whic intersect at a single point. This object exists in 6 dimensions, but can be projected to dimensions and thereby visualized:</p>
<p><img src="images/S1VS1VS1_Sammon.gif" width="300" height="300"></p>
<p>The software that was used to do the visualization is part of Simbrain (it was created by one of the authors and a mathematician; for more information click <a href="http://hisee.sourceforge.net/">here</a>), and so can be used to visualize structures in the high dimensional activation, weight, and input spaces of a neural network. </p>
<p>How does all this connect to dynamical systems theory? Recall that a dynamical system provides a rule for saying how a system changes state over time. The &quot;states&quot; of a system often correspond to vectors (or &quot;state vectors,&quot;) each of whose components is the state of a &quot;state variable.&quot; For example, the state of a neural network is often considered to be its activation vector. The set of all possible states of a system, e.g. all possible activation vectors for a neural network, is its <strong>state space.</strong> A dynamical system tells us how, from any point in state space (given any state vector for a system, e.g. any specification of activations for the nodes of a neural network), that system will evolve. In other words, for each point in state space, the dynamical system will tell us what points will be visited at all future times. </p>
<p class="heading2">State Space</p>
<p>Now, how does all of this apply to neural networks?</p>
<p>Recall from on earlier module that there are several standard features of neural networks which are understood as vectors: activation vectors, weight vectors or matrices, and input / output vectors. In every case we can think of the relevant sets of vectors as points in a vector space. This in turn allows us to visualize various aspects of neural networks. </p>
<p>Perhaps the most common case is that of activation vectors. The state of a neural network is generally taken to be an activation vector each of whose components corresponds to a state of one of its neurons. Thus, the state of a network with 20 nodes is a point in a 20-dimensional space. These can also, as we'll see in another module, be thought of as representations. </p>
<p>These are called &quot;activation spaces,&quot; and can be thought of as containing all the possible representations of a network. </p>
<p>Let us consider an example, which can be accessed by opening <span class="command">workspace &gt; lessons &gt; projection.xml</span>. The network in this example is a very simple network which reacts to objects around it. The network has four neurons, two input neurons each of which can taken on any value between 0 and 5, and binary outputs with a threshold of 3. The network is a very simple object detector, which responds to either fish or cheese but, because of the cross-cutting inhibitory synapses, does not respond to both together. </p>
<p>Since the network has four neurons, any pattern of activity in it is a 4-dimensional activation vector, that is, a point in a four dimensional space. As the network runs, reacting to the fish and cheese, different patterns of activity occur corresponding to different points in the four dimensional activation space. In the picture below, we see the full activation space of the network, and all the points that occur in that network given this environment. The red point is the point corresponding the current activation vector, (1, 0, 5, 0). Try moving the mouse around and you wil that the different points turn red as the state of the network changes. Remember that this is a <em>projection</em> of the 4 dimensional activation space of the network to the 2-dimensional gauge. </p>
<p><img src="images/GaugeExample1.png" width="842" height="276"></p>
<p>The structure of point in the activation space is interesting. There are two line-segments, one corresponding to each objects. The furthest point on each line segment corresponds to maximal exposure to one of the two objects. Note that the points which are furthest apart are the two maximal exposure points. The intermediate points correspond to states where the mouse is some intermediate distnace from the an object. And the point where the two line segments connect is the origin, (0,0,0,0). So you see we have a visual way of understanding the way neural networks organize and structure their activity and representations over time. </p>
<p>Another point about activation vectors is that they can be broken down into parts. Instead of thinking of the above as a vector in 4-space, we can think of it as involving two vectors in 2-space, an input vector and an output vector. (Technically, this is known as projecting a point in one space to a point in a corresponding subspace). We can separately plot these as follows:</p>
<p><img src="images/GaugeSubspace.png" width="435" height="223"></p>
<p>Note that the input space is a lot like the total activation space, just a bit smoother (there are &quot;bumps&quot; in the total space which come from the output node activities). The output space is just three points. One corresponding to recognizing cheese, one corresponding to recognizing fish, and one corresponding to rest. There is no point (1,1) corresponding to seeing both fish and cheese, because the inhibitory synapses prevent that. </p>
<p>Weight vectors are also points in a space with as many dimensions as there are weights (here it is easier to think of sets of weights as list vectors than as matrices, even though matrices are, in the strict mathematical sense, themselves vectors). For example, in the network above there are 16 synapses, and thus we have a point in a 16 dimensional &quot;weight space.&quot; Each point in weights space corresponds to a different set of weights, and hence a different manner of processing inputs and outputs, a different vector-valued function. We can imagine that points nearby will compute similar functions, while points far apart compute different functions. </p>
<p>Inputs are also point in a vector space. This allows us to compare and directly analyze the stimuli to a network. The input space. It is then interesting to see how patterns in this input space are converted into patterns in an intermediate hidden units spaces. We saw these input features above because the input nodes did not process the inputs to them, but rather just presented input values directly. </p>
<p>In the rest of this module we focus almost entirely on activation vectors and activation spaces.</p>
<p>Let us consider a a more realistic example. The whole brain can be thought of as being described by a huge state vector, which can be broken down into sub-vectors. The state of the visual cortex, which represents a visual scene in the world, is a pattern of activity over several million neurons, which can be represented by a million dimensional vector, which is a point in a millions dimensional space. We can now compare different states of the visual cortex by how close or far they are in &quot;visual cortex space.&quot; We can imagine that visual experiences of similar objects in similar lighting conditions are close to each other, while visual experineces of different objects are far away, and if we plotted these as points we would see the relevant distance relations.</p>
<p>All of this is very exciting in terms of understanding how the mind and brain work. We see the possibility of construing mental and neural activity in a way that can be visualized and mathematically analyzed. The possibility is opened of a geometry of mental processing. This point of view is part of what motivates philosophers to see connectionist networks as offering a useful way of understanding mind and brain. As the philosopher Paul Churchland put it in a 1986 article in <em>Mind</em>: </p>
<blockquote>
  <p>The basic idea&hellip;&nbsp; is that the brain represents various aspects of reality by a <em>position</em> in a suitable <em>state-space</em>; and the brain performs computations on such representations by means of general coordinate transformations from one state-space to another&hellip; The theory is entirely accessible&mdash;indeed, in its simplest form [under 3 dimensions] it is <em>visually</em> accessible (280). </p>
</blockquote>
<p class="heading2">Open Systems, Closed Systems, and Recurrent Networks </p>
<p>The neural network depicted above is not, strictly speaking, a dynamical system, because we cannot predict precisely what it will do from some fixed starting state. If you set the neurons at some level it can do different things, depending on what inputs are sent to it.  The problem is that the nueral network above is <em>open</em> to its enironment. A true dynamical system is fully predictable (&quot;deterministic&quot;), and to get that predictability, we have to shut it off from its environment, we have to make it in to a &quot;closed system.&quot; We can always do this in Simbrain simply by clicking the interaction button until the <img src="images/NeitherWay.gif" width="18" height="18">, appears, which means the net is not interacting with the world and the world is not interacting with networks. We can also do this simply by not creating any worlds.</p>
<p>So, suppose you have a  neural network closed off from any environment, from any &quot;world.&quot; This will be, almost automatically, a dynamical system (how can you make this <em>not </em>be a dynamical system? Some ways you could do this are to add noise to a neuron, or to use a random neuron or synapse, in which case we could not predict what it will do). However, most of the neural network's we've looked at have been <em>boring.</em>For example, the network below has boring dynamics on its own:</p>
<p><img src="images/Feedforward.png" width="278" height="187"></p>
<p>What makes the difference between a boring and interesting neural network from the standpoint of dynamical systems theory? The answer, roughly, is how much they will change their state when closed off. In the feed-forward networks shown above, when you put some activity in to the network it immediatley propagates along the connections and dissapears. In one or two time steps the network is back in its zero state. </p>
<p>How can we our neural networks exhibit more interesting dynamics, where activity does not just dissipate out but actually changes in an interesting way over time, independently of external inputs? The answer is simple: make some of the connections between neurons go &quot;backwards,&quot; as it were, so that activity will not just dissipate but will flow in loops back on itself. This is called recurrence. Here is an example of a recurrent network:</p>
<p><img src="images/recurrent_network.png" width="280" height="221"> </p>
<p>If you put this network in some initial state it may flicker around for a while before &quot;settling down.&quot; And it may never settle down at all. It may end up cycling through a few different states over time.</p>
<p class="heading2">Attractors, Basins of Attraction, Limit Cycles </p>
<p>Lets introduce a few ideas for describing dynamical systems. </p>
<p>First, an <strong>initial condition</strong> is an initial specification of values for the nodes of a neural network. When we arbitrarily set the neurons at some level of activation we are setting the network in an initial condition. An initial condition is a point in state space. To set a network in a variety of different initial conditions we can simply select all the nodes and press the randomization button repeatedly. </p>
<p>The sequence of states that occurs after we set the network in an initial condition and apply the dynamical rule (by pressing &quot;play&quot; in Simbrain) is called an <strong>orbit</strong> or <strong>trajectory</strong>. If we plot all the orbits from all the initial conditions in state space, we can get a sense of the way a system behaves. This kind of picture, of a bunch of orbits in state space, is called a <strong>phase portrait </strong>or<strong> flow.</strong> Here are a few sample phase portraits:</p>
<table width="200" border="0" cellspacing="10" cellpadding="10">
  <tr>
    <td><img src="images/Flow1.jpg" width="273" height="196"></td>
    <td><img src="images/flow2.gif" width="268" height="206"></td>
  </tr>
</table>
<p>These can be thought of phase portraits for 2-dimensional systems, i.e. 2-neuron neural networks. Again, any point in one of these diagrams corresponds to a state of the network, and the lines with arrows correspond to the subsequent states the network will be in. Of course, when investigating real neural networks, we will often be dealing with state spaces that are more than 2 dimensions, insofar as we are often dealing with neural networks with more than 2 neurons. In those cases we will view the phase portrait indirectly via a projection (the way orbits looks in a projection may be different from the way they really are; in particular, orbits can cross each other in a projection). Also note that the orbit for a discrete dynamical system, i.e,. a Simbrain network, will not involve smooth curves as in the pictures above, but sets of points nearby one another. </p>
<p>Now notice that in the flow on the left above, that most points lead to one place or another. These are called <strong>fixed points</strong>. This is a state of the network which, once it gets to, it stays at. If the network is in this point, it will not change. </p>
<p>Now consider points near a fixed points. If a fixed point is such that nearby points are drawn into it, then it is an attracting fixed point or <strong>attractor</strong>. An attractor is also thought of as an &quot;equilibrium,&quot; &quot;set point,&quot; or &quot;stable state&quot; of a neural network. In the diagram above and to the left is a flow with six attractors. If a fixed point is such that nearby points get away from it, it is a repelling fixed point or <strong>repellor</strong>. The point in the middle of the right-most flow above is a repellor. </p>
<p>An important thing to do when studying a neural network as a dynamical system is to find all the attractors, because these are the states the network will tend to be in. Attractors attract all nearby orbits. The set of all orbits attracted to a particular attractor is called a <strong>basin of attraction</strong>. Often you can partition a network into attractors, basins of attractions, and the regions between basins of attraction (which are repellors). Such a region is called a <strong>sepratrix</strong>. In the picture above and to the left right is no basin of attraction because there is no attractor; in the picture above and to the right there are six attractors and hence six basins, which are not pictured but which you can visualize relatively easily.One convenient metaphor for understanding basins of attraction and sepratrixes is the landscape or hill and valley metaphor. We can think of the state space of a neural network as being a curved surface, and the attractors as being valleys. The state of the network can be thought of as a marble on this surface, which will roll along paths (orbits) to the nearest valley. The basin of an attractor is the literal basin surrounding a low point. </p>
<p>Sometimes the network won't settle in to just one point, it will settle in to a kind of cycle where it goes through the same points over and over again. This is called a <strong>limit cycle</strong>. For discrete dynamical systems (which neural networks in Sibrain are), we can count how many points are in a limit cycle, and that corresponds to the <strong>period</strong> of the limit cycle. For example, a period-2 limit cycle consists of two points. A period 3 limit cycle consists of three points, etc. </p>
<p>Try creating the network above by creating four neurons and connecting them, randomizing the weights, and the repeatedly randomizing the nodes to initial conditions and pressing the <span class="command">step button</span>. You will quickly discover what the attractors and limit cycles of the network are. Notice also that if you make bigger networks you will get more different attractors and limit cycles. </p>
<p>There is much more to talk about with dynamical systems theory, but that's a good start. </p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</body>
</html>
