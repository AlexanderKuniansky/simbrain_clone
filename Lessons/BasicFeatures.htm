<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Basic Features</title>
<link href="Styles.css" rel="stylesheet" type="text/css">
<link href="../Cogs103/middle.css" rel="stylesheet" type="text/css" />
<link href="../Cogs103/navi.css" rel="stylesheet" type="text/css" />
</head>

<body>
  <a href='../Cogs103/index.html'><div class="header"><span></span></div></a>
  <div id="navcontainer">
  <ul>
  <li> <a href="http://www.simbrain.net/Cogs103/Syllabus_COGS_103.doc">The Syllabus</a> </li>
  <li><a href="http://www.simbrain.net/Downloads/downloads_main.html">Simbrain Download</a> </li>
  <li><a href="../Lessons/Contents.htm">Lessons / Labs</a></li>
  <li><a href="http://lists.husserl.net/mailman/listinfo/cogs_103">Mailing List</a> </li>
  <li><a href="Homeworks.html">Homework</a></li>
  <li><a href="http://www.simbrain.net/index_new.html">The Simbrain Page</a> </li>
  </ul>
  <div class="body">
<p><span class="heading">Basic Features of Neural Networks </span></p>
<p>The opening chapter of Rumelhart and McClelland's (1988) book, <em>Parallel Distributed Processing,</em> (the books that revived interest in neural network research) is entitled&quot;The Appeal of Parallel Distributed Processing.&quot; It was a kind of sales pitch for connectionism, and it was influential. Most the aspects of neural networks highlighted in that chapter are still relevant 20 years later, and indeed many introductory texts in neural networks begin with a discussion of these aspects.</p>
<p>In reviewing these features of neural networks so we are returning to a historical topic mentioned in another module. Soon after the MIT conference (to which some people trace cognitive science), a split developed between those who thought that cognition should be studied in terms of how the brain works, and those who thought that the brain was less important than the high level formal structure of cognition. Let us call this the distinction between &quot;Symbolic Artificial Intelligence&quot; or &quot;Symbolic AI&quot; and &quot;Connectionism.&quot; </p>
<p class="heading2">Symbolic AI vs. Connectionism </p>
<p>In the first camp are those who think of the mind as a rule-governed symbol processor. This position is also known as &quot;AI,&quot; &quot;Classical AI,&quot; &quot;Symbolic AI,&quot; and sometimes &quot;GOFAI&quot; (for &quot;Good Old Fashioned AI&quot;), among others. In its strongest form, it is the view that <em>the mind is to the brain as computer software is to computer hardware</em>. Some important features of this position are:</p>
<blockquote>
  <p><em>The brain is not important to studying cognition. </em>According to this view, what matters to cognitive science is the formal structure of cognition, not &quot;mere implementation&quot; details of the brain. Compare a computer program like Photoshop. Someone who wanted to know how photoshop works would care about its computer source code, but not about the transistors in the computer it runs on. On this view, what matters is high level formal structure, not low level neural details. </p>
  <p><em>Mental representations are symbol structures which have a linguistic form</em>. There is a &quot;language of thought,&quot; (sometimes called &quot;mentalese&quot;). For example, right now I am having the thought &quot;This computer is in front of me.&quot; All mental processes are based in operations on these symbol structures. </p>
  <p><em>Thinking involves applying explicit rules to symbolic structures. </em>For example, two minutes from now I can think &quot;that computer <em>was</em> in front of me&quot; by changing the tense of the verb &quot;is&quot; using a rule-based transformation &quot;is&quot; &gt; &quot;was.&quot; So while the elements of thought are symbol structures, the process of thinking consists in applying explicit rules to those structures. </p>
</blockquote>
<p>This is a very strong way of describing Classical AI, and many who believe in much of it would not say things this way (more below). I'm just setting up a strong contrast. </p>
<p>Connectionism has been put forward as an alternative to this. In Connectionism:</p>
<blockquote>
  <p><em>The brain is essential to studying cognition</em>. The way information is processed in the brain is the way it is processed in the mind. To understand the mind we need to understand the brain, and should use brain-like models. </p>
  <p><em>Mental representations correspond to patterns of activity across many nodes </em>. Thinking is not based on language-like  symbol structures, but on the patterns of activity of millions of neurons. Hence, the best models of information processing will involve operations on activation vectors. </p>
  <p><em>Thinking involves transforming  patterns of activity by patterns of  connections.</em> On this view, thinking involves transforming  patterns of activity by passing through complex webs of synaptic connections. Formally, this corresponds to transforming activation vectors as a function of weight matrices. </p>
</blockquote>
<p>So, whereas for symbolic AI the mind is a like a computer, filled with high level rules which operate on symbolically structured representations, for connectionism the mind is like the brain, transforming patterns of neural activity via complex webs of synaptic connections. </p>
<p>A few things to note before we go on. First, this is being presented as a sharp division, but many people operate in both camps, and today there are many who do &quot;hybrid&quot; work. For example, one can study &quot;connectionist symbol structures.&quot; Second, this division only matters to cognitive science. If you are an engineer, then you just use whatever works. For chess playing computers, Symbolic AI works better. For pattern recognition, neural networks work better.</p>
<p>Having seen the general division between symbolic AI and connectionism, let us move to some more specific distinctions. </p>
<p class="heading2">Neural Networks Operate in Parallel</p>
<p>Whereas regular digital computers do things one at a time, neural networks do a lot of things at the same time. Digital computers perform computations in <em>serial</em>, while neural networks perform computations in <em>parallel</em>.To see the difference, consider a simple problem: finding which of ten cups has a bean under it. A serial approach would lift each cup up, one at a time, until the bean was found. A parallel approach would lift all ten cups up at once.</p>
<p>Why not do everything in parallel? Parallel computation is clearly faster. The answer, roughly, is that digital computers are engineered to be reliable, to always work correctly. And part of that reliability comes from the fact that they do things one at a time. Sure, parallel is faster; but since contemporary processors are so fast this is not too much of a loss.  For example, the computer I'm writing this on performs several billion operations per second. With numbers like those we can tolerate the serial bottleneck. So serial processing is useful from an engineering standpoint (even the latest parallel processing computers are still fundamentally serial processors, they just distribute certain functions across those serial processors). </p>
<p>On the other hand, massively parallel processors like the brain are  messy, they make mistakes. They are not as good at computers at performing, e.g., complex mathematical computations or looking up names in an index. And they are made of relatively slow materials. Neurons fire at most 200 times per second. They are orders of magnitude slower then the transistors on this computer. In order to solve problems in a reasonable time frame the brain operates in parallel: every neuron is always doing its own thing. The trade-off is in accuracy: the brain is a kind of messy computer, which doesn't always do the same thing twice. But given the wet, biological stuff we're made of, it works well enough.</p>
<p>Things are not quite so clean in practice. First, even though neural networks are parallel, we run them on our serial computers. I'm guessing that if you run Simbrain, you are running it on a serial computer. That is, we<em> simulate parallel processing on serial computers</em>. But that doesn't matter--these are models after all; simulations aimed at studying how the real thing works. </p>
<p>Second, even though neural networks operate in parallel, many aspects of thinking of thinking are serial. As Rummelhart and McClelland point out:</p>
<blockquote>
  <p>The process of human cognition, examined on a time scale of seconds and minutes, has a distinctly sequential character to it. Ideas come, seem promising, and then are rejected; leads in the solution to a problem are taken up, then abandoned and replaced with new ideas... Clearly any useful description of the overall organization of this sequential flow of thought will necessarily describe a sequence of states (p. 12). </p>
</blockquote>
<p>But neural networks model the &quot;microstructure&quot; of cognition, what is sometimes called the &quot;sub-symbolic&quot; level of mental processing. Even if it is true that the overall behavior of our brain--patterns of firing across millions of neurons--flows from macro-pattern to macro-pattern sequentially, these high level processes are somehow grounded in low level processes involving thousands or millions of parallel computations. </p>
<p class="heading2">Neural Networks Gracefully Degrade </p>
<p>Classical, digital computers are &quot;brittle,&quot; in the sense that if a single component is lost there is a very good chance it will stop functioning properly. Knock out the microprocessor, or the clock, or snip a few wires, and the whole thing will stop running properly.</p>
<p>Neural networks, by contrast, gracefully degrade. If you lose a few neurons and /or synapses, there is a good chance that the whole system will continue to function well. Of course, if you lose enough neurons and synapses it will show, but the damage in performance is generally proportional to the damage to the network. The network degrades in performance&quot;gracefully.&quot; This is related to the fact that it operates in parallel rather than serial. While a serial computer needs to have every component lined up properly to work, a neural network has lots of redundant wiring which can compensate when problems arise. </p>
<p>It's easy to simulate graceful degradation in Simbrain. Create a network that does something and then start snipping out neurons or synapses. Does it keep working? How drastically is performance effected?</p>
<p class="heading2">Neural Networks are tolerant of Noisy Inputs</p>
<p>Digital computers don't like noisy input: they respond only to clean, precise inputs. Anyone who has worked with computers has some understanding of this. To get through a company's &quot;phone tree&quot; you have to enter just the right sequence of numbers, no mistakes allowed! Or, suppose you are looking me up in  a database. If you enter &quot;Joshimi&quot; instead of &quot;Yoshimi&quot; you won't find me. You must enter the exact right input to get the right response. (Of course Google and other computers can make good guesses, but then they are using technologies that may be inspired by neural network ideas; they are approximating neural network like computation in a digital computer).</p>
<p>Neural networks , on the other hand, do quite well with noisy inputs. Just look at our brains. Show me ten roses, and the exact pattern of stimulation on my retina will differ. In fact, show me the same rose ten times, and there is sure to be noise in the pattern produced on my retina. But I see it as a rose every time. We will see lots of examples of neural networks which keep chugging along even though the inputs presented to them are noisy. </p>
<p>Note that this is just graceful degradation applied to inputs rather than processing components. Brains do well with noisy, &quot;degraded&quot; inputs, but digital computers generally don't. </p>
<p class="heading2">Neural Networks use Distributed  Representations</p>
<p>Mental representations can be thought of in two ways: as being locally stored in one (or a small set of locations), or as being distributed over many locations. A local representation is, roughly, localized to one location of a system, whereas a distributed representation is stored in many parts of the system at once. </p>
<p>We can make this distinction entirely in the context of neural networks. A local representation in a neural networks is one that is &quot;local&quot; to a particular node. Let us say that a local representation in a neural network corresponds to a non-zero level of activation in just one unit. For example, in the network below blue cheese is given a local representation. It corresponds to receptor  5 (the neuron labeled &quot;Center 5&quot;) being activated. </p>
<p><img src="images/Local_Rep.png" width="624" height="335"></p>
<p>&nbsp;</p>
<p>In contrast, a distributed representation corresponds to an array of different levels of activation across a whole set of units. In the network below the bottle of poison has a distributed representation in the network. It corresponds to all five neurons being at different levels of activation between 0 and 1. </p>
<p><img src="images/Distributed_Rep.png" width="624" height="334"></p>
<p>Distributed representations are what one finds in the brain, for the most part. Generally speaking brain functions are distributed over many neurons. </p>
<p>Although it is harder to think about distributed representations directly, we see in another module how to visualize these patterns can be visualized as points in a space. This in turn makes it easier to visualize their relations to one another. </p>
<p>Some older types of neural network use only local representations, and we will see that it is sometimes useful to use local representations even in connectionist networks. However, the problem with local representations is that you lose some of the virtues above, in particular graceful degradation. If there is just one unit whose activation represents my grandmother, then if I lose that neuron I lose my whole memory of my grandmother. But that's just not plausible (it is sometimes derisively called the &quot;grandmother cell doctrine&quot;). Our brains just aren't that brittle. </p>
<p class="heading2">Conclusion</p>
<p>Neural networks operate in parallel on distributed continuous numerical data in such a way that they degrade gracefully and are tolerant of noisy data. Classical AI systems, by contrast, operate in serial on local, discrete, symbolic data in such a way that they degrade brittle and are not tolerant of noisy data. </p>
<p>The split between these two approaches continues to this day: for example, even today the role of neuroscience in cognitive science is a controversial topic. </p>
<p>But though I have set up a strong split between AI and connectionism, there are many today who do both. In a way it becomes a matter of what level of analysis you are at. If you are interested in low level perception, etc. connectionism is better, if you are interested in language processing, AI might be better. And I think most part theorists and working scientists have an ecumenical attitude. We have behavior, and we have the brain, and the two are connected. Choose the model that works best to describe the data you have, and if you're in a position to say how something mental is based in neural processes, so much the better. </p>
<p class="heading2">References</p>
<p><a href="http://www.macrovu.com/CCTGeneralInfo.html">http://www.macrovu.com/CCTGeneralInfo.html</a></p>
</body>
</html>
