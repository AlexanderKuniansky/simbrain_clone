<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Fundamentals of Neural Networks</title>
<link href="Styles.css" rel="stylesheet" type="text/css">
</head>

<body>
<h2 class="heading">Fundamentals of Neural Networks</h2>
<p>In this module we look at the different components of neural networks:  neurons, weights, and environmental inputs and outputs. First, however, it will be useful to think about what neural networks are models of.</p>
<p class="heading2">Connectionism and Cognitive Neuroscience </p>
<p>  Neural networks in cognitive science are used to study psychological processes as well as biological processes, and sometimes both. Before moving on it will be useful to have a clear sense of the difference between psychology and biology (neuroscience in particular). Both are empirical sciences in that they rely on  observations and measurements, but what they study and the kinds of measurements they make are different.</p>
<blockquote>
  <p><span class="heading2">Psychology</span>: For the most part psychologists measureme human and animal <em>behavior</em>. For example, to study perception human subjects are shown sensory cues (e.g. red dots on screens) and are asked to react to them. The cues and the reaction times are then measurements. Thus, psychology tends to study the overall, observable behavior of whole organisms.</p>
  <p><span class="heading2">Neuroscience</span>: Neuroscientists measure  human and animal brains. Common techniques include anatomy (direct observation of nerve tissue), often using stains; electrophysiology (sticking probes of various kinds into living creatures); and imaging (measuring activity of live brains using one of several imaging technologies). For example, to study how monkeys perceive stimuli, one can expose them to stimuli and then measure which neurons respond most. Or, to study how leech's bend one can put electrodes in them and measusre their biological neural networks as they bend.</p>
</blockquote>
<p>Very roughly, psychology studies the mind, neuroscience studies the brain; but whether the two are really different is, as mentioned elsewhere, a philosophical question. </p>
<p>Neural networks are used to model  both psychological and neuroscientific data,  and sometimes both.  Neuroscientists  who model the brain directly using computer models are sometimes called &quot;computational neuroscientists&quot; (note that not all computational neuroscientists use neural network models, but many do). Their models describe, sometimes in great detail, the mechanics of nerve cells, synapses, and other aspects of nervous systems. Those who model psychological phenomena  using neural networks are often called &quot;connectionists.&quot; Their models capture psychological using neuron-like elements, without much claim to biological realism. In fact there is a kind of continuum in neural network modeling between the two: </p>
<p align="center"><img src="images/ConnCompNeuro.gif" width="334" height="28"></p>
<p>&nbsp;</p>
<p>For any particular neural network model we can ask to what extent it is connectionist, and to what extent it is biological. This is definitely a continuum, in that some models are purely focused on biological or psychological data, while others try to capture both (e.g. a model of memory consolodation based on the structure of the hippocampus). </p>
<p>One way of answer this question, for any particular model, is to ask what the various nodes in a given neural network represent. Consider this model: </p>
<p align="center"><img src="images/simple_net.jpg" width="87" height="120"></p>
<p>Do the white circles represent actual neurons, groups of neurons, ideas, concepts, or what? Do the links between them represent actual synapses, collections of synapses between groups of neurons, connections between ideas, or what? The answer is closely related to where the network falls on the biology / psychology continuum. </p>
<p>It is important to note that all mathematical and computational models, regardless of the feature of reality they simulate, make <strong>simplifying assumptions</strong>. Simplifying assumptions are feature of the phenomenon being modelled which are not captured in the model itself. Simplifying assumptions are a necessity: in order to get a simulation off the ground certain aspects of the reality in question <em>have to be ignored</em>.&nbsp; For example, the connectionist models described below don't take account of the temperature of neurons, or of their many organelles (e.g. mitochondria). If we tried to capture everything we'd never get anywhere. But simplifying assumptions are important to keep in mind, so that we know what we are leaving out, and can revisit those things if necessary. Sometimes taking account of something not currently modelled can help capture more of a phenomenon than one would be able to otherwise. </p>
<p class="heading2">Basic Neuroscience </p>
<p>Even in the most abstract connectionist model the basic processing units capture certain basic features of the brain. Let us review these basic features.</p>
<p>Brains, like all organs, are made up of different kinds of cells. The cell's that have received the most attention from biologists and psychologists are neurons, which transmit information through the brain.</p>
<p>A real biological neuron is a cell (a &quot;nerve cell&quot;) like any other, which is specialized for transmitting electrical information in the brain. It has all the complex machinery any cell has, including mitochondria, golgi apparatus, a nucleus, and a complex membrane with tons of fancy proteins embedded in it. Of all this stuff what neural networks model is the way they take in information and pass it along. They do this via a few specialized structures:</p>
<blockquote>
  <p><strong>Dendrites</strong>: these are extensions that grow out of the cell body like a big root complex (dendrite in Latin means tree). You can think of them, for these purposes, as a giant catcher's mitt, because it is here that signals from other neurons are received, in the form of influxes of electrical charge, which affect the voltage of the neuron. </p>
  <p><strong>Soma</strong> or cell body: it is here that all the information from other neurons is summed together. If the voltage at the soma is sufficient, the neuron will fire an action potential along its axon. </p>
  <p><strong>Axon</strong>: this is another extension growing out of the cell body. They can be different lengths, but they are often longer than dendrites, having a long main extension and terminating in a branched structure. When the neuron fires an action potential, electrical activity propagates down these extensions, and stimulates dendrites of other neurons, and the process continues. The axon is like the arm of a pitcher, throwing signals to other dendrites which catch them. </p>
  <p> <strong>Synapses</strong>: these are not a part of neurons per se, but are rather the tiny junctions between neurons, where an axon touches (or almost touches) a dendrite. When an action potential reaches a synapse, chemicals are released into it, which open up channels on the dendrite of the connected neuron, which lets charge into it, and the process described above continues. Synapses can be stronger or weaker insofar as they pass more or less charge along. The actual connection is from a bouton on the pre-synaptic side to spine post-synaptically. Learning is believed to be based in the brain in changes that occur at synapses. </p>
</blockquote>
<p>These four structures and the aspects of them mentioned above correspond to the main features of the brain modelled by neural networks. Notice how many simplifying assumptions are being made: we are not looking at the temperature of the neurons, any of the organelles, etc. </p>
<p>Here is a picture which shows these  components:</p>
<p align="center"><img src="images/neuron_large.gif" width="257" height="344"> </p>
<p>The process begins at the top of this diagram, where a dendrite catches incoming signals. They are summed at the soma, and the signal is passed along via a synapse, shown in the inset. </p>
<p class="heading2">Artificial Neurons and Synapse</p>
<p>Computational neuroscientists  go pretty far in modeling neurons and synapses, and in another module we will see a bit about how this is done. But we begin by consider very simple connectionist models, in which simple processing units capture the basic information processes described above. Consider this simple, bare bones, connectionist network, from Simbrain:</p>
<p align="center"><img src="images/simple_net.jpg" width="166" height="230"> </p>
<p>The open circles model neurons, the filled circles represent synapses, and the input and output arrows represent a connection with an environment. Let us consider each of these, and the numbers associated with them. </p>
<blockquote>
  <p><strong>Simulated Neurons.</strong> Artifical neurons are associated with a quantity called &quot;activation.&quot;</p>
  <blockquote>
    <p><em>Also known as</em>: neurons, artificial neurons, processing units, nodes, units. </p>
    <p><em>What this models.</em> The activation of a node corresponds abstractly to a degree of activity. Pychologically, this is sometimes thought of as corresponding to the strength of an idea or belief. Biologically, this can be thought of in two ways: as representing at what rate a neuron is firing (but then what do negative values mean?). Or, what its voltage potential is (more on this later). </p>
    <p><em>Simbrain</em>: In Simbrain this is the number that shows up in the large circles, and corresponds to a color. The color itself can be set. </p>
  </blockquote>
  <p><strong>Simulated synapses.</strong> Artificial synpases or weights are  associated with a quantitiy called &quot;strength.&quot; </p>
  <blockquote>
    <p><em>Also known as</em>: weights, connections.</p>
    <p><em>What this models</em>: Abstractly, weight strength is a measure of how activity of one node influences that of another. Psychologically, this is sometimes thought of as  how strongly two ideas or beliefs are connected. Biologically, the strength of a weight represents how effective a synapse is in transmitting information from one neuron to another. What this corresponds to physically is not well known currently. It may be based on the number of receptors post-synaptically, or the amount of vesicles released by a particular synapse, or the number of actual spines on a connection.</p>
    <p><em>Learning: </em>The synapses change according to rules, usually rules that are slower than the activation rules. </p>
    <p><em>Simbrain</em>: In Simbrain this is represented by the color and a size of a filled disc. </p>
  </blockquote>
  <p><strong>Inputs and Ouptuts</strong>: We typically want neural networks to interact with an environment of some sort. That is we want to set the activations of some neurons (input neurons) based on something outside of the network, and we want the activations of other neurons (output neurons) to effect something outside of the network. </p>
  <blockquote>
    <p><em>Also known as</em>: couplings, sensors / motors, sensors / effectors, environment.</p>
    <p><em>What this models</em>: Abstractly, inputs and outputs correspond to a network's interface with the world beyond it. Biologically, at a high level inputs and outputs  correspond to sensory receptors and motor effectors, that allow us to convert energy in the environment into neural firings, and that allow those neural firings to be converted into our movement in the environment (or release of effectors into the blood-stream). But the inputs and outputs of a particular network can also be neurons that connect to other parts of the brain. For example the cerrebelum or visual cortex have inputs fromm other brain areas and output to other brain areas. </p>
    <p><em>Simbrain</em>: the nodes that take input from the envrionment have arrows facing in. Those that affect the environment have arrows facing out. There are various environments in Simbrain, which are called &quot;worlds.&quot; Neurons are connected to worlds using &quot;couplings,&quot; which specify which world a given neuron is connected to. </p>
    <p><em>Examples</em>:  In the simplest case we model an environnment simply by creating a set of numbers, sometimes called a &quot;corpus,&quot; which is given to the network, and then record the outputs. In Simbrain this is handled using a &quot;dataworld.&quot; In other cases the inputs are constructed from a simulated or virutal world, or the real world (e.g. a neural network in a robot), and the outputs are used to affect a simulated or virtual world. In Simbrain, &quot;odor world&quot; simulates simple reactions to objects, based on distance, in a 2-d world, and movements in the same. </p>
    <blockquote>
      <p>&nbsp;</p>
    </blockquote>
  </blockquote>
</blockquote>
<p class="heading2">Summary: what to ask when studying a connectionist network</p>
<p>When you encounter a neural network in cognitive science you should ask the following questions:</p>
<blockquote>
  <p>1) Where does it model? Does it model experimental data from psychology, or biological data from neuroscience?<br>
  2) What simplifying assumptions does it make. What details does it leave <em>out</em> of consideration.<br>
  3) What are the inputs and outputs to the network and what do they represent? </p>
</blockquote>
<p>&nbsp;</p>
</body>
</html>
