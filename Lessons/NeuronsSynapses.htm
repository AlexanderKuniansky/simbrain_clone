<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Fundamentals of Neural Networks</title>
<link href="Styles.css" rel="stylesheet" type="text/css">
</head>

<body>
<h2 class="heading">Fundamentals of Neural Networks</h2>
<p>In this module we look at the different components of neural networks:  neurons, weights, and environmental inputs and outputs. We will also think about the relationship between artificial neural networks and the things they are models of. </p>
<p><span class="heading2">Models and Simplifying Assumptions </span></p>
<p>We should begin by asking what a mathematical or computer model is, since artificial neural networks are such models. A &quot;model&quot; or &quot;simulation&quot; is an abstract representation of a real process. For example, on the news at night you often see computer models of the weather, which predict what the weather will be in the next few days. Such a model is not the same as the real thing; it leaves certain things out, and focuses on others, in order to do its work. </p>
<p>All mathematical and computational modes make <strong>simplifying assumptions</strong>. Simplifying assumptions are features of the phenomenon being modeled which are not captured in the model itself. Simplifying assumptions are a necessity: in order to get a simulation off the ground certain aspects of the reality in question <em>have to be ignored</em>.&nbsp; For example, simulations of the weather don't take account of birds or airplanes in the sky: those details are just too specific to matter to the predictions they make, and would just slow the simulation down. If a model tried to capture everything about reality it would never get anywhere. But simplifying assumptions are important to keep in mind, so that we know what we are leaving out, and so we can revisit those things if necessary.</p>
<p class="heading2">Connectionism and Cognitive Neuroscience </p>
<p>What are artificial neural networks models of? Well, at the first pass, biological neural networks. But it is not always so simple. In fact depending on the context, neural networks are models of different things. Neural networks in cognitive science are sometimes used to model biological neural networks, sometimes to model psychological processes, and sometimes both. </p>
<p>What is the difference? Well, let us first consider the difference between psychology and biology (neuroscience in particular). Both are empirical sciences in that they rely on  observations and measurements, but what they study and the kinds of measurements they make are different.</p>
<blockquote>
  <p><span class="heading2">Psychology</span>: For the most part psychologists measure human and animal <em>behavior</em>. For example, to study perception human subjects are shown sensory cues (e.g. red dots on screens) and are asked to react to them. The cues and the reaction times are then measurements. Thus, psychology tends to study the overall, observable behavior of whole organisms.</p>
  <p><span class="heading2">Neuroscience</span>: Neuroscientists measure  human and animal brains. Common techniques include anatomy (direct observation of nerve tissue), often using stains; electrophysiology (sticking probes of various kinds into living creatures); and imaging (measuring activity of live brains using such indirect measures as sugar metabolism). For example, to study how monkeys perceive stimuli, one can expose them to stimuli while recording their neurons.</p>
</blockquote>
<p>Neural networks are used to model  both psychological and neuroscientific data,  and sometimes both. </p>
<blockquote>
  <p><span class="heading2">Computational Neuroscience</span>:  Neuroscientists  who model the brain directly using computer models are sometimes called &quot;computational neuroscientists&quot; (not all computational neuroscientists use neural network models, but many do). Their models describe, sometimes in great detail, the mechanics of nerve cells, synapses, and other aspects of nervous systems. </p>
  <p><strong class="heading2">Connectionism</strong>: Those who model psychological phenomena  using neural networks are often called &quot;connectionists.&quot; Their models capture psychological phenomena using neuron-like elements, without much claim to biological realism. </p>
</blockquote>
<p>In fact there is a kind of continuum in neural network modeling between the two: </p>
<p align="center"><img src="images/ConnCompNeuro.gif" width="334" height="28"></p>
<p>&nbsp;</p>
<p>For any particular neural network model we can ask to what extent it is a connectionist model of psychological processes, and to what extent it is computational neuroscience model of biological processes. This is  a continuum, in that some models are purely focused on biological data or psychological data, while others try to capture both (e.g. a model of how memory are formed based on the structure of the hippocampus, which is a structure in the brain). </p>
<p>We will see below that we need to ask these questions when looking at any particular neural network. Do its nodes represent actual neurons, groups of neurons, ideas, concepts, or what? Do the links between them represent actual synapses, collections of synapses between groups of neurons, connections between ideas, or what? </p>
<p class="heading2">Basic Neuroscience </p>
<p>Even in the most abstract connectionist model the basic processing units capture certain basic features of the brain. Let us review these basic features.</p>
<p>Brains, like all organs, are made up of different kinds of cells. The cells that have received the most attention from biologists and psychologists are neurons, which transmit information through the brain.</p>
<p>A real biological neuron is a cell (a &quot;nerve cell&quot;) like any other, which is specialized for transmitting electrical information in the brain. It has all the complex machinery any cell has, including mitochondria, golgi apparatus, a nucleus, and a complex membrane with tons of fancy proteins embedded in it. Of all this stuff what neural networks model is the way they take in information and pass it along (the rest is usually left out; these are thus simplifying assumptions of most neural models). </p>
<p>Neurons transmit information using a few specialized structures:</p>
<blockquote>
  <p><strong>Dendrites</strong>: these are extensions that grow out of the cell body like a big root complex (&quot;dendrite&quot; comes fro a Latin word which means &quot;tree&quot;). You can think of dendrites as being a giant catchers mitt, because it is here that signals from other neurons are received, in the form of influxes of electrical charge.</p>
  <p><strong>Soma</strong> or cell body: it is here that all the information from other neurons is summed together. If there is enough voltage at the soma, the neuron will fire an action potential along its axon. </p>
  <p><strong>Axon</strong>: this is another extension growing out of the cell body. Axons can be different lengths, but they are often longer than dendrites, having a long main extension and terminating in a branched structure. When the neuron fires an &quot;action potential,&quot; electrical activity propagates down these extensions, and stimulate dendrites of other neurons, and the process continues. Continuing our baseball metaphor, the axon is like the arm of a pitcher, throwing signals to other dendrites which catch them. </p>
  <p> <strong>Synapses</strong>: these are not a part of neurons per se, but are rather the tiny junctions between neurons, where an axon touches (or almost touches) a dendrite. When an action potential reaches a synapse, chemicals are released into it, which open up channels on the dendrite of the connected neuron, which let charge into it, and the process described above continues.  Learning is believed to be based in the brain in changes that occur at synapses, and thereby affect the way information is passed from one neuron to another. Two additional terms will be useful in what follows:</p>
  <blockquote>
    <p> <em>Pre-synaptic neuron:</em> this is the neuron on axonal side of a synapse, the source neuron which is transmitting information.</p>
    <p><em>Post-synaptic neuron</em>. this is the neuron on the dendritic side of a synapse, the target neuron which is receiving information.</p>
  </blockquote>
</blockquote>
<p>These four structures and the aspects of them mentioned above correspond to the main features of the brain modeled by neural networks. Notice how many simplifying assumptions are being made: we are not looking at the temperature of the neurons, any of the organelles, the surrounding glial cells or blood vessels, etc. </p>
<p>Here is a picture which shows these  components:</p>
<p align="center"><img src="images/neuron_large.gif" width="257" height="344"> </p>
<p>The process begins at the top of this diagram, where a dendrite catches incoming signals. These signals are summed at the soma, passed down the axon via an action potential, and transmitted to the next neuron at the synapse, shown in the inset. </p>
<p class="heading2">Artificial Neurons and Synapse</p>
<p>Computational neuroscientists  go pretty far in modeling neurons and synapses, and in another module we will see a bit about how this is done. But we begin by considering a bare-bones  connectionist model which captures the basic information processing described above. Consider this simple network from Simbrain:</p>
<p align="center"><img src="images/simple_net.jpg" width="166" height="230"> </p>
<p>The open circles model neurons, the filled circles represent synapses, and the input and output arrows represent a connection with an environment. Let us consider each of these, and the numbers associated with them. </p>
<blockquote>
  <p><strong>Simulated Neurons.</strong> Artificial neurons are associated with a quantity called &quot;activation.&quot; </p>
  <blockquote>
    <p><em>Also known as</em>: neurons, artificial neurons, processing units, nodes, units. </p>
    <p><em>What this models.</em> The activation of a node corresponds abstractly to a degree of activity. Psychologically, this is sometimes thought of as corresponding to the strength of an idea or belief. Biologically, this can be thought of in two ways: as representing at what rate a neuron is firing, or what its voltage potential is (more on this later). </p>
    <p><em>Simbrain</em>: In Simbrain neurons are represented by  circles, and activation level corresponds to a color. </p>
  </blockquote>
  <p><strong>Simulated synapses.</strong> Artificial synapses or weights are  associated with a quantity called &quot;strength.&quot; Changes in weight strength correspond to learning, in a neural network model. </p>
  <blockquote>
    <p><em>Also known as</em>: weights, connections.</p>
    <p><em>What this models</em>: Abstractly, weight strength is a measure of how activity of one node influences that of another. Psychologically, this is sometimes thought of as  how strongly two ideas or beliefs are connected. Biologically, the strength of a weight represents how affective a synapse is in transmitting information from one neuron to another. What this corresponds to physically is not well known currently. It may be based on the number of receptors post-synaptically, or the amount of vesicles released by a particular synapse, or the number of &quot;spines&quot; there are receiving signals on the post-synaptic side of a synapse. </p>
    <p><em>Simbrain</em>: In Simbrain this is represented by the color and a size of a filled circle. The actual strength of a weight can be seen by double clicking on it or lingering over it. </p>
  </blockquote>
  <p><strong>Inputs and Outputs</strong>: We typically want neural networks to interact with an environment of some sort. That is we want to set the activations of some neurons (input neurons) based on an environment outside of the network, and we want the activations of other neurons (output neurons) to affect the environment. For example, in a model of reading the inputs are visual cues in the environment, written words, and the outputs are spoken words, that is, sound waves.</p>
  <blockquote>
    <p><em>Also known as</em>: couplings, sensors / motors, sensors / effectors, environment.</p>
    <p><em>What this models</em>: Abstractly, inputs and outputs correspond to a network's interface with the world beyond it. Biologically, at a high level, inputs and outputs  correspond to sensory receptors and motor effectors, that allow us to convert energy in the environment into neural firings, and that allow those neural firings to be converted into our movement in the environment. But the inputs and outputs of a particular network can also be neurons that connect to other parts of the brain. For example the cerebellum or visual cortex have inputs from other brain areas and make outputs to other brain areas. </p>
    <p><em>Simbrain</em>: the nodes that take input from the environment have arrows facing in. Those that affect the environment have arrows facing out. There are various environments in Simbrain, which are called &quot;worlds.&quot; Neurons are connected to worlds using &quot;couplings,&quot; which specify which world a given neuron is connected to. </p>
    <p><em>Examples</em>:  In the simplest case we model an environment simply by creating a set of numbers, sometimes called a &quot;corpus,&quot; which is given to the network, and then record the outputs. In Simbrain this is handled using a &quot;dataworld.&quot; In other cases the inputs are constructed from a simulated or virtual world, or the real world (e.g. a neural network in a robot), and the outputs are used to affect a simulated or virtual world. In Simbrain, &quot;odor world&quot; simulates simple reactions to objects, based on distance, in a 2-d world, and movements in the same. </p>
    <blockquote>&nbsp;</blockquote>
  </blockquote>
</blockquote>
<p class="heading2">Summary: what to ask when studying a connectionist network</p>
<p>When you encounter a neural network in cognitive science you should ask the following questions:</p>
<blockquote>
  <p>1) Where does it model? Does it model experimental data from psychology, or biological data from neuroscience?<br>
  2) What simplifying assumptions does it make? What details does it leave <em>out</em> of consideration.<br>
  3) What are the inputs and outputs to the network and what do they represent? </p>
</blockquote>
<p>&nbsp;</p>
</body>
</html>
